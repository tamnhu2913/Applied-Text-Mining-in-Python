{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamnhu2913/Applied-Text-Mining-in-Python/blob/main/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "042ddd35e206e7e1391c875e9a6ed367",
          "grade": false,
          "grade_id": "cell-c1591794d1fd86d3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "N7r5yIquc7vU"
      },
      "source": [
        "# Assignment 2 - Introduction to NLTK\n",
        "\n",
        "In part 1 of this assignment you will use nltk to explore the <a href='http://www.cs.cmu.edu/~ark/personas/'>CMU Movie Summary Corpus</a>. All data is released under a <a href='https://creativecommons.org/licenses/by-sa/3.0/us/legalcode'>Creative Commons Attribution-ShareAlike License</a>. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3aaa75831c5da066cadbe61915e4ac73",
          "grade": false,
          "grade_id": "cell-3d80a2d0f0db2240",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pJ7ei6h9c7vY"
      },
      "source": [
        "## Part 1 - Analyzing Plots Summary Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ba66628bfe1eeef83f2c719a13c75a0e",
          "grade": false,
          "grade_id": "cell-e90899706f77f111",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dVe32mpTc7vY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5c2a34-155b-4a21-83aa-d2f76c2f3bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "nltk.data.path.append(\"assets/\")\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "\n",
        "# If you would like to work with the raw text you can use 'plots_raw'\n",
        "with open('assets/plots.txt', 'rt', encoding=\"utf8\") as f:\n",
        "    plots_raw = f.read()\n",
        "\n",
        "# If you would like to work with the plot summaries in nltk.Text format you can use 'text1'.\n",
        "plots_tokens = nltk.word_tokenize(plots_raw)\n",
        "text1 = nltk.Text(plots_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "79da98b604c58196f7ab060d37b80738",
          "grade": false,
          "grade_id": "cell-1b05eeb0d5ba2354",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DbXOW5l9c7vZ"
      },
      "source": [
        "### Example 1\n",
        "\n",
        "How many tokens (words and punctuation symbols) are in text1?\n",
        "\n",
        "*This function should return an integer.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "69df2d758fcc798f64ce17b1fdd977e3",
          "grade": false,
          "grade_id": "cell-1ba7b4619cb7493e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "fT_EiJm6c7vZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2633d08-d02d-44bc-d1ca-0a7d7688fc4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "374446"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "def example_one():\n",
        "\n",
        "    return len(nltk.word_tokenize(plots_raw)) # or alternatively len(text1)\n",
        "\n",
        "example_one()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bb0e377d6239813d9388dbfeacae633e",
          "grade": false,
          "grade_id": "cell-a98e3f30e25ba849",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "BZ8s-46Ic7va"
      },
      "source": [
        "### Example 2\n",
        "\n",
        "How many unique tokens (unique words and punctuation) does text1 have?\n",
        "\n",
        "*This function should return an integer.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bc467f7cae3620b83a6ba7dfb0cf821e",
          "grade": false,
          "grade_id": "cell-7d9049c605f475c0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "EEoEViUvc7vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d4c8a5-27b2-4d84-b3cd-d293560522ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25928"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "def example_two():\n",
        "\n",
        "    return len(set(nltk.word_tokenize(plots_raw))) # or alternatively len(set(text1))\n",
        "\n",
        "example_two()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4b42347544bd4ad5a4351f8664477944",
          "grade": false,
          "grade_id": "cell-e718058d7a91011b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9uzfuVFBc7vb"
      },
      "source": [
        "### Example 3\n",
        "\n",
        "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
        "\n",
        "*This function should return an integer.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "803b60144a4be3736540c0d8d36ad560",
          "grade": false,
          "grade_id": "cell-2f40f5a1c59b5994",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qzzz7ot3c7vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e69551-733b-42a8-c802-f45fc93024b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21755"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def example_three():\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
        "\n",
        "    return len(set(lemmatized))\n",
        "\n",
        "example_three()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c35433373631a4b873cbc1b9be20dbb0",
          "grade": false,
          "grade_id": "cell-17b1215308416fc7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "d7zLYd3rc7vc"
      },
      "source": [
        "### Question 1\n",
        "\n",
        "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
        "\n",
        "*This function should return a float.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a8d36786c19fc59c793052acd5399b32",
          "grade": false,
          "grade_id": "cell-1ffaa79138a71fb9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ymCA7WA2c7vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "607d2e69-7f8f-438c-8840-ec59e0a669e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06924362925495264"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "def answer_one():\n",
        "    return example_two()/example_one()\n",
        "\n",
        "answer_one()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4bdca0afdbe07ebe551cdab9a36a5453",
          "grade": true,
          "grade_id": "cell-f652837013625f3e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "gc2Rb11Wc7vc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "40f67e855292d55876456d71e04ac9ad",
          "grade": false,
          "grade_id": "cell-58eedbdc1473445b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "StEQNtkPc7vd"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "What percentage of tokens is 'love'or 'Love'?\n",
        "\n",
        "*This function should return a float.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2496b2469c600cb15fb4eaab26d122cf",
          "grade": false,
          "grade_id": "cell-f93ee77c9ff6ba52",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "IeBQCg2ac7vd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d014cf0-2b49-47bd-be8b-4e73f2310124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0012391639916035956"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "def answer_two():\n",
        "  from nltk.probability import FreqDist\n",
        "  token_lower = [w.lower() for w in plots_tokens]\n",
        "  dist = FreqDist(token_lower)\n",
        "  return dist['love'] / len(token_lower)\n",
        "\n",
        "answer_two()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9bf647cc1d14c656c8ec8541a3ead648",
          "grade": true,
          "grade_id": "cell-27092be2e8e84d2e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "JDH4Nv-Vc7vd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "4071b0e5cbc34d71aae894c92ad1786b",
          "grade": false,
          "grade_id": "cell-c09aa76a3f984318",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1tWujmBfc7vd"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
        "\n",
        "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "afcb9aac78dfd68e33cdc2cbc6ab3f50",
          "grade": false,
          "grade_id": "cell-62c8d073f91273ac",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "qWbKIHLac7vd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de567812-d062-4938-bd28-0080d974513b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 19420),\n",
              " ('the', 18698),\n",
              " ('.', 16629),\n",
              " ('to', 12149),\n",
              " ('and', 11400),\n",
              " ('a', 8979),\n",
              " ('of', 6510),\n",
              " ('is', 5699),\n",
              " ('in', 5109),\n",
              " ('his', 4693),\n",
              " (\"'s\", 3682),\n",
              " ('her', 3674),\n",
              " ('he', 3556),\n",
              " ('that', 3517),\n",
              " ('with', 3293),\n",
              " ('him', 2570),\n",
              " ('for', 2433),\n",
              " ('by', 2321),\n",
              " ('The', 2234),\n",
              " ('on', 1925)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "def answer_three():\n",
        "  from nltk.probability import FreqDist\n",
        "  dist = FreqDist(plots_tokens)\n",
        "  return dist.most_common(20)\n",
        "\n",
        "answer_three()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ae9b1e8a351ce37ede871f5a80797619",
          "grade": true,
          "grade_id": "cell-507a8849d081756b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "OZV5C5p1c7vd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f420b6c683e5a2697cb390cfd2d231ae",
          "grade": false,
          "grade_id": "cell-5f47fe4f238b78dd",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "SKgu9NTOc7ve"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "What tokens have a length of greater than 5 and frequency of more than 200?\n",
        "\n",
        "*This function should return an alphabetically sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8473f68f68831b3534011887e16eba2b",
          "grade": false,
          "grade_id": "cell-5a6acdef4847e737",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "9aBuDANOc7vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9f561f-a397-4887-8100-f6b1c19ee8f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['However',\n",
              " 'Meanwhile',\n",
              " 'another',\n",
              " 'because',\n",
              " 'becomes',\n",
              " 'before',\n",
              " 'begins',\n",
              " 'daughter',\n",
              " 'decides',\n",
              " 'escape',\n",
              " 'family',\n",
              " 'father',\n",
              " 'friend',\n",
              " 'friends',\n",
              " 'himself',\n",
              " 'killed',\n",
              " 'leaves',\n",
              " 'mother',\n",
              " 'people',\n",
              " 'police',\n",
              " 'returns',\n",
              " 'school',\n",
              " 'through']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "def answer_four():\n",
        "  from nltk.probability import FreqDist\n",
        "  dist = FreqDist(plots_tokens)\n",
        "  vocab = dist.keys()\n",
        "  return sorted([w for w in vocab if len(w) > 5 and dist[w] > 200])\n",
        "\n",
        "answer_four()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "597a65b1cd8276d5c0a471f5e3c1cb71",
          "grade": true,
          "grade_id": "cell-dfac54d8588a79bb",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WONEFCJmc7vf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6b5811c65dd5af6e6bfc2f7e6120a4b9",
          "grade": false,
          "grade_id": "cell-8ea845b3204e681f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "U_OBf2pYc7vf"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Find the longest token in text1 and that token's length.\n",
        "\n",
        "*This function should return a tuple `(longest_word, length)`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b92f5d1417c21499c76d69eb96fecea0",
          "grade": false,
          "grade_id": "cell-8e48b990b889617c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "N77XIPG_c7vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e62942-fc7c-423d-b715-c868fbe350d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('live-for-today-for-tomorrow-we-die', 34)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "def answer_five():\n",
        "  long_words = max(plots_tokens, key = len)\n",
        "  return (long_words, len(long_words))\n",
        "\n",
        "answer_five()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "302b42ce329c3690975289c8cac7512c",
          "grade": true,
          "grade_id": "cell-8f427855b0328b18",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ir60hawMc7vf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "210c5a24a1359d3a83749e138733bc26",
          "grade": false,
          "grade_id": "cell-79422bcd3ea94729",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "HuP973k8c7vf"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "What unique words have a frequency of more than 2000? What is their frequency?\n",
        "\n",
        "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
        "\n",
        "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6c9d107058699448b6fceec5870e0961",
          "grade": false,
          "grade_id": "cell-b361bd2f0c973ddf",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "HAWixpK7c7vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582e812a-062f-4583-ff92-bb668971b32c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(18698, 'the'),\n",
              " (12149, 'to'),\n",
              " (11400, 'and'),\n",
              " (8979, 'a'),\n",
              " (6510, 'of'),\n",
              " (5699, 'is'),\n",
              " (5109, 'in'),\n",
              " (4693, 'his'),\n",
              " (3674, 'her'),\n",
              " (3556, 'he'),\n",
              " (3517, 'that'),\n",
              " (3293, 'with'),\n",
              " (2570, 'him'),\n",
              " (2433, 'for'),\n",
              " (2321, 'by'),\n",
              " (2234, 'The')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "def answer_six():\n",
        "  from nltk.probability import FreqDist\n",
        "  dist = FreqDist(plots_tokens)\n",
        "  vocab = dist.keys()\n",
        "  return sorted([(dist[w], w) for w in vocab if w.isalpha() and dist[w] > 2000], reverse=True)\n",
        "\n",
        "answer_six()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c99cd375d565984825eab962a92bc069",
          "grade": true,
          "grade_id": "cell-e6629ec7a557e797",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "-T5C5bnEc7vg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "39a16f37b4a68b256c52e6949612e82e",
          "grade": false,
          "grade_id": "cell-a5232dd39b79ce55",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "osDA733yc7vg"
      },
      "source": [
        "### Question 7\n",
        "\n",
        "`text1` is in `nltk.Text` format that has been constructed using tokens output by `nltk.word_tokenize(plots_raw)`.\n",
        "\n",
        "Now, use `nltk.sent_tokenize` on the tokens in `text1` by joining them using whitespace to output a sentence-tokenized copy of `text1`. Report the average number of whitespace separated tokens per sentence in the sentence-tokenized copy of `text1`.\n",
        "\n",
        "*This function should return a float.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "09a27a55e10b9c22c801f688baacc689",
          "grade": false,
          "grade_id": "cell-416275d058421b1c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "InMm88S7c7vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5bc185-d58a-4508-c784-05e1b3265065"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.30172721858249"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "def answer_seven():\n",
        "  sents = nltk.sent_tokenize(plots_raw)\n",
        "  return len(plots_tokens)/len(sents)\n",
        "\n",
        "answer_seven()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "458127acbf8bd0fd20c2fcb66d0152c6",
          "grade": true,
          "grade_id": "cell-11a1faa1d07cef4c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UOg2RusPc7vg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "dd8f86d60dc3cef696b2f64515d39ac3",
          "grade": false,
          "grade_id": "cell-377489593984f88c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qIOPddFXc7vg"
      },
      "source": [
        "### Question 8\n",
        "\n",
        "What are the 5 most frequent parts of speech in `text1`? What is their frequency?\n",
        "\n",
        "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3403e39852d8e5d7783a908b64c73c57",
          "grade": false,
          "grade_id": "cell-2fb8ade1035d010e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "coPgczQ7c7vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd79d6f-c6d0-4e31-96a0-a6443404f386"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NN', 51450), ('IN', 39225), ('NNP', 38360), ('DT', 34471), ('VBZ', 23799)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "def answer_eight():\n",
        "  from nltk.probability import FreqDist\n",
        "  pos_tagging = nltk.pos_tag(plots_tokens)\n",
        "  freq = FreqDist([tag for (word, tag) in pos_tagging])\n",
        "  return freq.most_common(5)\n",
        "\n",
        "answer_eight()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eaa2738338890ba15a3b87d2a53e5af3",
          "grade": true,
          "grade_id": "cell-1ea3284952623d77",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "8KLg-MvNc7vh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0cc5797124305c841c1d47f9f94a25fb",
          "grade": false,
          "grade_id": "cell-8b2318e9cdf5078e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "WGoxiBbec7vh"
      },
      "source": [
        "## Part 2 - Spelling Recommender\n",
        "\n",
        "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
        "\n",
        "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
        "\n",
        "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
        "\n",
        "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "441445a0d079ca69464ef89648261329",
          "grade": false,
          "grade_id": "cell-9635cab5394b4243",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Db4pXgXBc7vh"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import words\n",
        "\n",
        "correct_spellings = words.words()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "eeb154a2ba138d89531b09d030c96b88",
          "grade": false,
          "grade_id": "cell-f9bd4901b8b76756",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Ce7On62Lc7vh"
      },
      "source": [
        "### Question 9\n",
        "\n",
        "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
        "\n",
        "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
        "\n",
        "Refer to:\n",
        "- [NLTK Jaccard distance](https://www.nltk.org/api/nltk.metrics.distance.html?highlight=jaccard_distance#nltk.metrics.distance.jaccard_distance)\n",
        "- [NLTK ngrams](https://www.nltk.org/api/nltk.util.html?highlight=ngrams#nltk.util.ngrams)\n",
        "\n",
        "*This function should return a list of length three:\n",
        "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f0a14e318e39c3a250b6de233f1b72fb",
          "grade": false,
          "grade_id": "cell-49250d9f337abe33",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "N3dNM5wyc7vh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87b5c0a-fa6a-4030-a9ff-645dc45eaa93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corpulent', 'indecence', 'validate']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
        "  from nltk.metrics.distance import jaccard_distance\n",
        "  from nltk.util import ngrams\n",
        "  entries=['cormulent', 'incendenece', 'validrate']\n",
        "  df = pd.DataFrame(correct_spellings, columns = ['words'])\n",
        "  arr = []\n",
        "  def calculate_jaccard(word, entry):\n",
        "    word_ngrams = set(ngrams(word, 3))  # Tạo ngrams 3 cho từ\n",
        "    target_ngrams = set(ngrams(entry, 3))  # Tạo ngrams 3 cho 'cormulent'\n",
        "    return jaccard_distance(word_ngrams, target_ngrams)\n",
        "\n",
        "  for entry in entries:\n",
        "    temp = df[df['words'].str.startswith(entry[0])].reset_index(drop=True)\n",
        "    temp['distance'] = temp['words'].apply(lambda x: calculate_jaccard(x, entry))\n",
        "    arr.append(temp.loc[temp['distance'].argmin(),'words'])\n",
        "  return arr\n",
        "\n",
        "answer_nine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c6b7225fdb774f5e46dec50d7f3d0219",
          "grade": true,
          "grade_id": "cell-2a2de5b65d33eeeb",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "k5HHA0HKc7vh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c4fdc471c5def474f7508040daa46f23",
          "grade": false,
          "grade_id": "cell-e529b7b60545aced",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2mDL8hAnc7vh"
      },
      "source": [
        "### Question 10\n",
        "\n",
        "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
        "\n",
        "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
        "\n",
        "Refer to:\n",
        "- [NLTK Jaccard distance](https://www.nltk.org/api/nltk.metrics.distance.html?highlight=jaccard_distance#nltk.metrics.distance.jaccard_distance)\n",
        "- [NLTK ngrams](https://www.nltk.org/api/nltk.util.html?highlight=ngrams#nltk.util.ngrams)\n",
        "\n",
        "*This function should return a list of length three:\n",
        "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "51f67cfcb3cd3f0f54de42c21d665328",
          "grade": false,
          "grade_id": "cell-d2c7a9b21cb77476",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "lfoPpCAnc7vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7f05be-58d4-4e51-8ce4-a627aaf050f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cormus', 'incendiary', 'valid']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
        "  from nltk.metrics.distance import jaccard_distance\n",
        "  from nltk.util import ngrams\n",
        "  entries=['cormulent', 'incendenece', 'validrate']\n",
        "  df = pd.DataFrame(correct_spellings, columns = ['words'])\n",
        "  arr = []\n",
        "  def calculate_jaccard(word, entry):\n",
        "    word_ngrams = set(ngrams(word, 4))  # Tạo ngrams 3 cho từ\n",
        "    target_ngrams = set(ngrams(entry, 4))  # Tạo ngrams 3 cho 'cormulent'\n",
        "    return jaccard_distance(word_ngrams, target_ngrams)\n",
        "\n",
        "  for entry in entries:\n",
        "    temp = df[df['words'].str.startswith(entry[0])].reset_index(drop=True)\n",
        "    temp['distance'] = temp['words'].apply(lambda x: calculate_jaccard(x, entry))\n",
        "    arr.append(temp.loc[temp['distance'].argmin(),'words'])\n",
        "  return arr\n",
        "\n",
        "answer_ten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "76a6ddaac45438536958b0b37387cd95",
          "grade": true,
          "grade_id": "cell-7a14f4e02e15bfa2",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "F8kQAblBc7vm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "784c5b952d5fa2e6fd55c834b255ef96",
          "grade": false,
          "grade_id": "cell-6d6d7fb064f4d28a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ioobJYn3c7vm"
      },
      "source": [
        "### Question 11\n",
        "\n",
        "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
        "\n",
        "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
        "\n",
        "Refer to:\n",
        "- [NLTK edit distance](https://www.nltk.org/api/nltk.metrics.distance.html?highlight=edit_distance#nltk.metrics.distance.edit_distance)\n",
        "\n",
        "*This function should return a list of length three:\n",
        "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6d4b6f99a1ea16548f0abc19381a53b8",
          "grade": false,
          "grade_id": "cell-f1e44797650980f3",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "1hacKG8Yc7vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75badcc-62f8-4f84-a428-d3b5df7719d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['corpulent', 'intendence', 'validate']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
        "  from nltk.metrics.distance import edit_distance\n",
        "  entries=['cormulent', 'incendenece', 'validrate']\n",
        "  df = pd.DataFrame(correct_spellings, columns = ['words'])\n",
        "  arr = []\n",
        "\n",
        "  for entry in entries:\n",
        "    temp = df[df['words'].str.startswith(entry[0])].reset_index(drop=True)\n",
        "    temp['distance'] = temp['words'].apply(lambda x: edit_distance(x, entry))\n",
        "    arr.append(temp.loc[temp['distance'].argmin(),'words'])\n",
        "  return arr\n",
        "\n",
        "answer_eleven()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c06a959d158d7d93ceeae13dee2de62e",
          "grade": true,
          "grade_id": "cell-152ee7cd1d36928c",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "_Pm5qqrIc7vn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "coursera": {
      "course_slug": "python-text-mining",
      "graded_item_id": "r35En",
      "launcher_item_id": "tCVfW",
      "part_id": "NTVgL"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (v3.10.8:aaaf517424, Oct 11 2022, 10:14:40) [Clang 13.0.0 (clang-1300.0.29.30)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}